} 
  ans = 4.9000 4.1000 
  >>net.b{1} 
  ans = 
  2.3000 
  这和用adapt训练出来的结果是一样的。在静态网络中，adapt函数能够根据输入数据格
式的不同应用于增加方式和批处理方式。
如果数据用同步向量矩阵方式输入就用批处理方式
训练；如果数据用异步方式输入就用增加方式。但这对于train函数行不通，无论输入格式如
何，它总是采用批处理方式。 
  动态网络中的增加方式 
  训练静态网络相对要简单一些。如果我们用train训练网络，即使输入是异步向量细胞数
组，它也是转变成同步向量矩阵而采用批处理方式。如果我们用adapt。输入格式决定着网
络训练方式。如果传递的是序列，网络用增加方式，如果传递的是同步向量就采用批处理方
式。 
  在动态网络中，批处理方式只能用train完成，特别是当仅有一个训练序列存在时。为了
说明清楚，让我们重新考虑那个带延迟的线性网络。我们把学习速率设为0.02（当我们采用
梯度下降算法时，
我们要用比增加方式更小的学习速率，
应为所有的分立的梯度都要在决定
权重改变步进之前求和） 
  net = newlin([-1 1],1,[0 1],0.02); 
  net.IW{1,1}=[0 0]; 
  net.biasConnect=0; 
  net.trainParam.epochs = 1; 
  Pi = {1}; 
  P = {2 3 4}; 
  T = {3 5 6}; 
  我们用以前增加方式训练过的那组数据训练，
但是这一次我们希望只有在所有数据都提
交后才更新权重（批处理方式）
。因为输入是一个序列，网络将用异步模式模拟。但是权重
将用批处理方式更新。 
  net=train(net,P,T,Pi); 
  经过一次训练后，权重值为： 
  >>net.IW{1,1} 
  ans = 0.9000 0.6200 
  这里的权重值和我们用增加方式得到的不同。在增加方式中，通过训练设置，一次训练
可以更新权重三次。在批处理方式中，每次训练只能更新一次。 
 
第三章 反向传播网络（BP网络） 
 
  1．概述 
  前面介绍了神经网络的结构和模型，
在实际应用中，
我们用的最广泛的是反向传播网络
（BP网络）
。下面就介绍一下BP网络的结构和应用