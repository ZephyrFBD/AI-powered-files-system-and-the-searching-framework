.lr= 0.2; 
  为有序训练设置的最后一个参数是net.adaptParam.passes，
它决定在训练过程中训练值重
复的次数。这里设置重复次数为200 
  net.adaptParam.passes = 200; 
  现在我们就可以开始训练网络了。当然我们要指定输入值和目标值如下所示： 
  p = [-1 -1 2 2;0 5 0 5]; 
  t = [-1 -1 1 1]; 
  如果我们要在每一次提交输入后都更新权重，
那么我们需要将输入矩阵和目标矩阵转变
为细胞数组。每一个细胞都是一个输入或者目标向量。 
  p = num2cell(p,1); 
  t = num2cell(t,1); 
  现在就可以用adapt来实现增加方式训练了: 
  [net,a,e]=adapt(net,p,t); 
  训练结束以后，我们就可以模拟网络输出来检验训练质量了。 
  a = sim(net,p) 
  a = 
  [-0.9995] [-1.0000] [1.0001] [1.0000] 
  带动力的梯度下降法(LEARDGDM) 
  除了learngd以外，
还有一种增加方式算法常被用到，
它能提供更快的收敛速度--learngdm,
带动量的最速下降法。
动力允许网络不但根据当前梯度而且还能根据误差曲面最近的趋势响
应。就像一个低通滤波器一样，动量允许网络忽略误差曲面的小特性。没有动量，网络又可
能在一个局部最小中被卡住。
有了动量网络就能够平滑这样的最小。
动量能够通过把权重变
得与上次权重变化的部分和由算法规则得到的新变化的和相同而加入到网络学习中去。
上一
次权重变化对动量的影响由一个动量常数来决定，
它能够设为0 到1 之间的任意值。
当动量
常数为0 时，
权重变化之根据梯度得到。
当动量常数为1 时新的权重变化等于上次的权重变
化，梯度值被忽略了。 
  Learngdm函数有上面所示的learngd函数触发，
除非mc和lr学习参数都被设置了。
由于每
一个权重和偏置有它自己的学习参数，每一个权重和偏置都可以用不同的参数。 
  下面的命令将用lerangdm为前面建立的用增加方式训练的网络设置缺省的学习参数： 
  net.biases{1,1}.learnFcn = 'learngdm'; 
  net.bias