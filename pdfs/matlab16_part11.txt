这是缺省的线性网络调整函数。learnwh是缺省
的权重和偏置学习函数。因此，Widrow-Hoff学习法将会被使用： 
  [net,a,e,pf] = adapt(net,P,T); 
  a = 0 0 0 0 
  e = 4 5 7 7 
  注意网络的输出全部为0，因为在所有要训练的数据提交前权重没有被更新，如果我们
显示权重，我们就会发现： 
  >>net.IW{1,1} 
  ans = 4.9000 4.1000 
  >>net.b{1} 
  ans = 
  2.3000 
  经过了用adapt函数的批处理方式调整，这就和原来不一样了。 
  现在用train函数来实现批处理方式。由于Widrow-Hoff规则能够在增加方式和批处理方
式中应用，它可以通过adapt和train触发。我们有好几种算法只能用于批处理方式（特别是
Levenberg-Marquardt算法）
，所以这些算法只能用train触发。 
  网络用相同的方法建立： 
  net = newlin([-1 1;-1 1],1,0,0.1); 
  net.IW{1,1} = [0 0]; 
  net.b{1} = 0; 
  在这种情况下输入向量即能用同步向量矩阵表示也能用异步向量细胞数组表示。
用train
函数，任何异步向量细胞数组都会转换成同步向量矩阵。这是因为网络是静态的，并且因为
train总是在批处理方式中使用。
因为MATLAB实现同步模式效率更高，
所以只要可能总是采
用同步模式处理。 
  P = [1 2 2 3; 2 1 3 1]; 
  T = [4 5 7 7]; 
  现在我们开始训练网络。由于我们只用了一次adapt，我们这里训练它一次。缺省的线
性网络训练函数是trainwb。learnwh是缺省的权重和偏置学习函数。因此，我们应该和前面
缺省调整函数是adaptwb的例子得到同样的结果。 
  net.inputWeights{1,1}.learnParam.lr = 0.1; 
  net.biases{1}.learnParam.lr = 0.1; 
  net.trainParam.epochs = 1; 
  net = train(net,P,T); 
  经过一次训练后，我们显示权重发现： 
  >>net.IW{1,1