。 
  BP网络是采用Widrow-Hoff学习算法和非线性可微转移函数的多层网络。
一个典型的BP
网络采用的是梯度下降算法，也就是Widrow-Hoff算法所规定的。backpropagation就是指的
为非线性多层网络计算梯度的方法。
现在有许多基本的优化算法，
例如变尺度算法和牛顿算
法。
神经网络工具箱提供了许多这样的算法。
这一章我们将讨论使用这些规则和这些算法的
优缺点。 
  一个经过训练的BP网络能够根据输入给出合适的结果，
虽然这个输入并没有被训练过。
这个特性使得BP网络很适合采用输入/目标对进行训练，而且并不需要把所有可能的输入/
目标对都训练过。为了提高网络的适用性，神经网络工具箱提供了两个特性--规则化和早期
停止。
这两个特性和用途我们将在这一章的后面讨论。
这一章还将讨论网络的预处理和后处
理技术以提高网络训练效率。 
 
  2．基础 
  网络结构 
  神经网络的结构前一章已详细讨论过，前馈型BP网络的结构结构和它基本相同，这里
就不再详细论述了，这里着重说明以下几点： 
  1． 常用的前馈型BP网络的转移函数有logsig，tansig，有时也会用到线性函数purelin。
当网络的最后一层采用曲线函数时，
输出被限制在一个很小的范围内，
如果采用线性函数则
输出可为任意值。以上三个函数是BP网络中最常用到的函数，但是如果需要的话你也可以
创建其他可微的转移函数。 
  2． 在BP网络中，转移函数可求导是非常重要的，tansig、logsig和purelin都有对应的导
函数dtansig、
dlogsig和dpurelin。
为了得到更多转移函数的导函数，
你可以带字符"deriv"的转
移函数： 
  tansig('deriv') 
  ans = dtansig 
  网络构建和初始化 
  训练前馈网络的第一步是建立网络对象。函数newff建立一个可训练的前馈网络。这需
要4 个输入参数。第一个参数是一个Rx2 的矩阵以定义R个输入向量的最小值和最大值。第
二个参数是一个颟顸每层神经元个数的数组。
第三个参数是包含每层用到的转移函数名称的
细胞数组。最后一个参数是用到的训练函数的名称。 
  举个例子，下面命令将创建一个二层网络,其网络模型如下图所示。 
 
  
  
  它的输入是两个元素的向量，第一层有