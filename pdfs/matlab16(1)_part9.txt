这一节中我们将示范怎样把增加方式应用到这两种网络中去。 
  静态网络中的增加方式 
  继续考虑前面用过的第一个静态网络的例子，
我们用增加方式来训练它，
这样每提交一
次输入数据，网络权重和偏置都更新一次。在这个例子里我们用函数adapt，并给出输入和
目标序列： 
  假定我们要训练网络建立以下线性函数： 
  t=2p1+p2 
  我们以前用的输入是： 
  
 
  目标输出是： 
  t1=[4],t2=[5] ,t3=[7] ,t4=[7]  
  我们首先用0 初始化权重和偏置。
为了显示增加方式的效果，
我们把学习速度也设为0。
 
  net = newlin([-1 1;-1 1],1,0,0); 
  net.IW{1,1} = [0 0]; 
  net.b{1} = 0; 
  为了用增加方式，我们把输入和目标输出表示为以下序列： 
  P = {[1;2] [2;1] [2;3] [3;1]}; 
  T = {4 5 7 7}; 
  前面的讨论中，不论是作为一个同步向量矩阵输入还是作为一个异步向量细胞数组输
入，模拟的输出值是一样的。而在训练网络时，这是不对的。当我们使用adapt 函数时，如
果输入是异步向量细胞数组，那么权重将在每一组输入提交的时候更新（就是增加方式）
，
我们将在下一节看到，
如果输入是同步向量矩阵，
那么权重将只在所有输入提交的时候更新
（就是批处理方式）
。 
  我们现在开始用增加方式训练网络： 
  [net,a,e,pf] = adapt(net,P,T); 
  由于学习速度为0，网络输出仍然为0，并且权重没有被更新。错误和目标输出相等。 
  a = [0] [0] [0] [0] 
  e = [4] [5] [7] [7] 
  如果我们设置学习速度为0.1，我们就能够看到当每一组输入提交时，网络是怎么调整
的了。 
  net.inputWeights{1,1}.learnParam.lr=0.1; 
  net.biases{1,1}.learnParam.lr=0.1; 
  [net,a,e,pf] = adapt(net,P,T); 
  a = [0] [2] [6.0] [5.8] 
  e = [4] [3] [1.0] [1.2] 
  由于在第一个输入数据提交前还没有更新