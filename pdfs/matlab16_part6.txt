，偏置向量b 和输出向量a。为了区分这
些权重矩阵、输出矩阵等等，在图中的每一层，我们都为感兴趣的变量以上标的形式增加了
层数。你能够看到在下面所示的三层网络图和等式中使用层符号。 
 
  
  
  上面所示的网络有R1 个输入，第一层有S1 个神经元，第二层有S2 个神经元，以次类
推。一般不同层有不同数量的神经元。每一个神经元的偏置输入是常量1。 
  注意中间层的输出就是下一层的输入。
第二层可看作有S1 个输入，
S2 个神经元和S1xS2 
阶权重矩阵W2 的单层网络。第二层的输入是a1，输出是a2，现在我们已经确定了第二层
的所有向量和矩阵，我们就能把它看成一个单层网络了。其他层也可以照此步骤处理。 
  多层网络中的层扮演着不同的角色。
给出网络输出的层叫做输出层。
所有其他的层叫做
隐层。上图所示的三层网络有一个输出层（第三层）和两个隐层（第一和第二层）
。有些作
者把输入作为第四层，这里不用这种指定。 
  上面所示的三层网络的简洁画法如下图所示： 
 
  
  
  多层网络的功能非常强大。
举个例子，
一个两层的网络，
第一层的转移函数是曲线函数，
第二层的转移函数是线性函数，通过训练，它能够很好的模拟任何有有限断点的函数。这种
两层网络集中应用于"反向传播网络"。 
注意我们把第三层的输出a3 标记为y。我们将使用这种符号来定义这种网络的输出。 
 
  4．数据结构 
  这一节将讨论影响网络仿真的输入数据结构的格式。
我们首先讨论静态网络，
在讨论动
态网络。 
  我们将关心两种基本的输入向量类型：同步（同时或者无时序）向量和异步向量。对异
步向量来说，向量的顺序是非常重要的。对同步向量来说，顺序是不重要的，并且如果我们
已经有一定数量的并行网络我们就能把一个输入向量输入到其中的任意网络。 
  静态网络中的同步输入仿真 
  仿真静态网络（没有反馈或者延迟）是网络仿真最简单的一种。在这种情况中，我们不
需要关心向量输入的时间顺序，所以我们可以认为它是同时发生的。另外，为了是问题更简
单，我们假定开始网络仅有一个输入向量。我们用下面的网络作为例子。 
  为了建立这个网络我们可以用以下命令： 
 
  
  
  net = newlin([-1 1;-1 1],1); 
  简单起见我们假定权重矩阵和偏置为： 
  W=[1，2