的网络，
它缺省用initnw来初始化第一层。
如果我们想要用rands重新初始化
第一层的权重和偏置，我们用以下命令： 
  net.layers{1}.initFcn = 'initwb'; 
  net.inputWeights{1,1}.initFcn = 'rands'; 
  net.biases{1,1}.initFcn = 'rands'; 
  net.biases{2,1}.initFcn = 'rands'; 
  net = init(net); 
  网络模拟(SIM) 
  函数sim 模拟一个网络。sim 接收网络输入p，网络对象net，返回网络输出a，这里是
simuff用来模拟上面建立的带一个输入向量的网络。 
  p = [1;2]; 
  a = sim(net,p) 
  a = 
  -0.1011 
  (用这段代码得到的输出是不一样的，这是因为网络初始化是随机的。) 
  下面调用sim来计算一个同步输入3 向量网络的输出： 
  p = [1 3 2;2 4 1]; 
  a=sim(net,p) 
  a = 
  -0.1011 -0.2308 0.4955 
  网络训练 
  一旦网络加权和偏差被初始化，
网络就可以开始训练了。
我们能够训练网络来做函数近
似（非线性 后退）
，模式结合，或者模式分类。训练处理需要一套适当的网络操作的例子--
网络输入p 和目标输出t 。在训练期间网络的加权和偏差不断的把网络性能函数 
net.performFcn减少到最小。
前馈网络的缺省性能函数是均方误差mse--网络输出和目标输出t
之间的均方误差。
这章的余项将描述几个对前馈网络来说不同的训练算法。
所有这些算法都
用性能函数的梯度来决定怎样把权重调整到最佳。
梯度由叫做反向传播的技术决定，
它要通
过网络实现反向计算。
反向传播计算源自使用微积分的链规则。
基本的反向传播算法的权重
沿着梯度的负方向移动，
这将在下一节讲述。
以后的章节将讲述更复杂的算法以提高收敛速
度。 
  反向传播算法 
  反向传播算法中有许多变量，
这一章将讨论其中的一些。
反向传播学习算法最简单的应
用是沿着性能函数最速增加的方向--梯度的负方向更新权重和偏置。这种递归算法可以写
成： 
  xk+1 = xk- a k g k  
  